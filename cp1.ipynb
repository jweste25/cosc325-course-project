{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2b161a",
   "metadata": {},
   "source": [
    "# Aninmal Shelter - Dog Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c62e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1d3af",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6332fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'data/labels.csv'\n",
    "labels=pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b43ce49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: 0\n"
     ]
    }
   ],
   "source": [
    "# List of filenames\n",
    "image_dir = 'data/train/'\n",
    "filenames = [image_dir + fname + '.jpg' for fname in labels['id']]\n",
    "\n",
    "# Check if any files do not exist\n",
    "missing_files = [fname for fname in filenames if not os.path.isfile(fname)]\n",
    "print(f\"Missing files: {len(missing_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9569fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "X = filenames\n",
    "y = labels['breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cf59473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(labels[['breed']])\n",
    "encoding_labels = encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae944afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Subset for building\n",
    "X_train_subset = X_train[:1000]\n",
    "X_val_subset = X_val[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6760ed",
   "metadata": {},
   "source": [
    "## Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0af49262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for image and batch size\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# PyTorch image transforms - creates a preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)), #resizes all the images\n",
    "    transforms.ToTensor(), #converts to tensorflow images\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # converts 0-1 to -1 to 1\n",
    "])\n",
    "# Get number of classes\n",
    "num_classes = len(encoding_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e67d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class DogBreedDataset(Dataset):\n",
    "    #constructor\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "      #determines the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    #called by PyTorch to get a specific item\n",
    "    def __getitem__(self, idx):\n",
    "        # Load and process image\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Return image and label\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b2b4e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 120\n"
     ]
    }
   ],
   "source": [
    "# Convert breed names to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_subset_encoded = label_encoder.fit_transform(y_train[:1000])\n",
    "y_val_subset_encoded = label_encoder.transform(y_val[:1000])\n",
    "\n",
    "print(f\"Number of classes: {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b66dcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets and dataloaders\n",
    "def create_data_loaders(X_train, y_train, X_val, y_val, batch_size=BATCH_SIZE):\n",
    "    #Create PyTorch DataLoaders for training and validation\"\"\"\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DogBreedDataset(X_train, y_train, transform)\n",
    "    val_dataset = DogBreedDataset(X_val, y_val, transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ece8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1000\n",
      "Validation samples: 1000\n",
      "Number of classes: 120\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Create PyTorch DataLoaders\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_loader, val_loader, train_dataset, val_dataset = create_data_loaders(\n",
    "    X_train_subset, \n",
    "    y_train_subset_encoded, \n",
    "    X_val_subset, \n",
    "    y_val_subset_encoded,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Verify everything is working\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
