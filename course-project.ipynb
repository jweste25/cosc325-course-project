{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2b161a",
   "metadata": {},
   "source": [
    "# Aninmal Shelter - Dog Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c62e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "# Add TensorFlow path (needed for this Windows installation)\n",
    "sys.path.insert(0, r'C:\\tf_temp')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1d3af",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2e1f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "TensorFlow imported successfully!\n",
      "Test tensor: b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow installation from C:\\tf_temp\n",
    "import sys\n",
    "sys.path.insert(0, r'C:\\tf_temp')\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(\"TensorFlow imported successfully!\")\n",
    "    \n",
    "    # Test basic functionality\n",
    "    hello = tf.constant('Hello, TensorFlow!')\n",
    "    print(f\"Test tensor: {hello}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"TensorFlow import failed: {e}\")\n",
    "    print(\"Try the manual registry edit option instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6332fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'data/labels.csv'\n",
    "labels=pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b43ce49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: 0\n"
     ]
    }
   ],
   "source": [
    "# List of filenames\n",
    "image_dir = 'data/train/'\n",
    "filenames = [image_dir + fname + '.jpg' for fname in labels['id']]\n",
    "\n",
    "# Check if any files do not exist\n",
    "missing_files = [fname for fname in filenames if not os.path.isfile(fname)]\n",
    "print(f\"Missing files: {len(missing_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9569fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "X = filenames\n",
    "y = labels['breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf59473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(labels[['breed']])\n",
    "encoding_labels = encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae944afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Subset for building\n",
    "X_train_subset = X_train[:1000]\n",
    "X_val_subset = X_val[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6760ed",
   "metadata": {},
   "source": [
    "## Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af49262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for image and batch size\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e67d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to preprocess the images\n",
    "def process_image(image_path):\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b2b4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to return a tuple (image, label)\n",
    "def get_image_label(image_path, label):\n",
    "  image = process_image(image_path)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b66dcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets from the file paths and labels\n",
    "def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "    # If the data is a test dataset, we probably don't have have labels\n",
    "    if test_data:\n",
    "        print(\"Creating test data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n",
    "        data_batch = data.map(process_image).batch(batch_size)\n",
    "        return data_batch\n",
    "    \n",
    "    # If the data is a valid dataset, we don't need to shuffle it\n",
    "    elif valid_data:\n",
    "        print(\"Creating validation data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n",
    "                                                   tf.constant(y))) # labels\n",
    "        data_batch = data.map(get_image_label).batch(batch_size)\n",
    "        return data_batch\n",
    "    \n",
    "    else:\n",
    "        print(\"Creating training data batches...\")\n",
    "        # Turn filepaths and labels into Tensors\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n",
    "                                                   tf.constant(y))) # labels\n",
    "        \n",
    "        # Shuffling pathnames and labels before mapping image processor function is faster than shuffling the mapped data\n",
    "        data = data.shuffle(buffer_size=len(X))\n",
    "        \n",
    "        # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
    "        data = data.map(get_image_label)\n",
    "        \n",
    "        # Turn the training data into batches\n",
    "        data_batch = data.batch(batch_size)\n",
    "    return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8ece8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training and validation data batches...\n",
      "Creating training data batches...\n",
      "Creating validation data batches...\n",
      "Training batches: 32\n",
      "Validation batches: 32\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation data batches\n",
    "print(\"Creating training and validation data batches...\")\n",
    "\n",
    "# Create training data batches (shuffled)\n",
    "train_data = create_data_batches(X_train_subset, y_train[:1000])\n",
    "\n",
    "# Create validation data batches (not shuffled)\n",
    "val_data = create_data_batches(X_val_subset, y_val[:1000], valid_data=True)\n",
    "\n",
    "print(f\"Training batches: {len(train_data)}\")\n",
    "print(f\"Validation batches: {len(val_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
